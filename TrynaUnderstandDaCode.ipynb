{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'file_path', 'extension', 'text', 'Language', 'Work',\n",
       "       'Summaries', 'Skill', 'Member', 'Writing', 'Researching', 'Honor',\n",
       "       'Activity', 'candidate_name', 'email', 'phone', 'GPA', 'greeklife',\n",
       "       'certifications', 'latin_honors', 'top_10_universities',\n",
       "       'top_100_universities', 'other_universities', 'major_minor',\n",
       "       'associate_education_level', 'bachelor_education_level',\n",
       "       'master_education_level', 'doctor_education_level', 'courses',\n",
       "       'languages', 'Education', 'Extracurriculars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/output/resume_summary.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Education','latin_honors','top_10_universities','top_100_universities', 'other_universities',\n",
    "         'associate_education_level', 'bachelor_education_level', 'master_education_level', \n",
    "         'doctor_education_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                                       28\n",
       "file_path                                   ../data/input/resumes/Resume 6.pdf\n",
       "extension                                                                 .pdf\n",
       "text                         \\t\\n  \\n\\nANN\\t\\n  K.\\t\\n  EITRHEIM\\t\\n  \\n\\nP...\n",
       "Language                                                                   NaN\n",
       "Work                         EXPERIENCE\\t\\n  \\nSummer\\t\\n  Financial\\t\\n  A...\n",
       "Summaries                                                                  NaN\n",
       "Skill                        SKILLS\\t\\n  \\n\\n•  Microsoft\\t\\n  Office\\t\\n  ...\n",
       "Member                                                                     NaN\n",
       "Writing                                                                    NaN\n",
       "Researching                                                                NaN\n",
       "Honor                        HONORS\\t\\n  \\n\\n•  Order\\t\\n  of\\t\\n  Omega\\t\\...\n",
       "Activity                                             ACTIVITIES\\t\\n  AND\\t\\n  \n",
       "candidate_name                                                       NOT FOUND\n",
       "email                                                   ann.eitrheim@drake.edu\n",
       "phone                                                   ('952', '412', '8888')\n",
       "GPA                                                                         []\n",
       "greeklife                                                       {'fraternity'}\n",
       "certifications                                 {'Chartered Financial Analyst'}\n",
       "latin_honors                                                               NaN\n",
       "top_10_universities                                                        NaN\n",
       "top_100_universities                                                       NaN\n",
       "other_universities                                                         NaN\n",
       "major_minor                            {'Economics', 'Accountancy', 'Finance'}\n",
       "associate_education_level                                                  NaN\n",
       "bachelor_education_level                                                   NaN\n",
       "master_education_level                                                     NaN\n",
       "doctor_education_level                                                     NaN\n",
       "courses                                                                    NaN\n",
       "languages                                                                  NaN\n",
       "Education                    EDUCATION\\t\\n  \\t\\n  \\nDrake\\t\\n  University,\\...\n",
       "Extracurriculars                                                           NaN\n",
       "Name: 28, dtype: object"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EDUCATION     Drake  University,  Des  Moines,  IA               •      BSBA  Accounting  and  Finance  majors,  Economics  minor   2014  Level  I  Candidate  in  the  CFA  Program  (Sitting  for  on  December  6th,  2014)   '"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Education[i].replace('\\n',' ').replace('\\xa0','').replace('\\t','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in df.Member[df.Member == df.Member]:\n",
    "#     print(re.sub(' +',' ',i.replace('\\\\n','. ').replace('\\n','. ')))\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for num in range(0,60):\n",
    "#     try:\n",
    "#         input_string = re.sub('[;-]', ',',df.Summaries[num].replace('\\n',' '))\n",
    "#         input_string = re.sub('[_]', ' ',input_string)\n",
    "#         input_string = re.sub(' +', ' ',input_string)\n",
    "#         print('\\n')\n",
    "#         print(input_string)\n",
    "#         doc = nlp(input_string) \n",
    "#         doc_entities = doc.ents \n",
    "#         for i in doc_entities:\n",
    "#         #     if i.label_ == 'PERSON':\n",
    "#             print(i, '   ', i.label_)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_list = set()\n",
    "for i in df.index:\n",
    "    if df.Member[i] == df.Member[i]:\n",
    "\n",
    "        doc = nlp(str(df.Edu[i]).replace('\\\\n', '. ').replace('\\n', '. '))\n",
    "        doc_entities = doc.ents\n",
    "        doc_persons = filter(lambda x: x.label_ == 'ORG', doc_entities)\n",
    "        doc_persons = filter(lambda x: len(x.text.strip().split()) >= 2, doc_persons)\n",
    "        doc_persons = map(lambda x: x.text.strip(), doc_persons)\n",
    "        doc_persons = list(doc_persons)\n",
    "        for j in doc_persons:\n",
    "            university_list.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array(list(university_list))\n",
    "x = pd.DataFrame(np.sort(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/api/annotation#named-entities\n",
    "TYPE\tDESCRIPTION\n",
    "PERSON\tPeople, including fictional.\n",
    "NORP\tNationalities or religious or political groups.\n",
    "FAC\tBuildings, airports, highways, bridges, etc.\n",
    "ORG\tCompanies, agencies, institutions, etc.\n",
    "GPE\tCountries, cities, states.\n",
    "LOC\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "PRODUCT\tObjects, vehicles, foods, etc. (Not services.)\n",
    "EVENT\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "WORK_OF_ART\tTitles of books, songs, etc.\n",
    "LAW\tNamed documents made into laws.\n",
    "LANGUAGE\tAny named language.\n",
    "DATE\tAbsolute or relative dates or periods.\n",
    "TIME\tTimes smaller than a day.\n",
    "PERCENT\tPercentage, including ”%“.\n",
    "MONEY\tMonetary values, including unit.\n",
    "QUANTITY\tMeasurements, as of weight or distance.\n",
    "ORDINAL\t“first”, “second”, etc.\n",
    "CARDINAL\tNumerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To look at sections of the YAML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# with open('/Users/anneitrheim/PycharmProjects/Capstone/confs/config.yaml', 'r') as stream:\n",
    "#     try:\n",
    "#         data_loaded = yaml.safe_load(stream)\n",
    "#     except yaml.YAMLError as exc:\n",
    "#         print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame()\n",
    "# for i in data_loaded['extractors']['universities']:\n",
    "#     if type(i) == list:\n",
    "#         df = df.append(pd.Series(i), ignore_index=True)\n",
    "#     else:\n",
    "#         df = df.append(pd.Series(i), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['one', 'two', 'three']\n",
    "# df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For word2vec on the resumes we have in our repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/output/resume_summary.csv')\n",
    "df.drop(['extension'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "   \n",
    "def remove_stop_words(x):\n",
    "    try:\n",
    "  \n",
    "        x = x.replace('___',' ')\n",
    "        x = x.replace('\\n',' ')\n",
    "        x = x.replace('\\r',' ')\n",
    "        x = x.replace('\\t',' ')\n",
    "        x = x.replace('\\s',' ')\n",
    "\n",
    "        x = re.sub('[^A-Za-z ]+', '', x)\n",
    "        \n",
    "        word_tokens = word_tokenize(x)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        return ' '.join(filtered_sentence)\n",
    "    except:\n",
    "        print(x.values)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "resumes=df['text'].apply(remove_stop_words)\n",
    "# store as list of lists of words\n",
    "resumes_ted = []\n",
    "for sent_str in resumes:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "    resumes_ted.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM=300\n",
    "w2v=Word2Vec(resumes_ted, #the list of split resumes\n",
    "             size=EMB_DIM, #the dimensionality of the embedding vector\n",
    "             window=5, #Maximum distance between the current and predicted word within a sentence\n",
    "             min_count=3, #Ignores all words with total frequency lower than this (to keep only valid real words)\n",
    "             negative=15, #Negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20)\n",
    "             iter=20, #Number of iterations (epochs) over the corpus\n",
    "             workers=multiprocessing.cpu_count()) #number of threads being used\n",
    "vectors=w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-917166681e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'university'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "vectors.most_similar(positive=['university'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking to see if it parsed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('data/output/resume_summary.csv')\n",
    "# df1.drop(['extension'], axis=1, inplace=True)\n",
    "\n",
    "# import re\n",
    "# def remove_stop_words(x):\n",
    "#     x = str(x)\n",
    "#     x = x.replace('___',' ')\n",
    "#     x = x.replace('\\n',' ')\n",
    "#     x = x.replace('\\r',' ')\n",
    "#     x = x.replace('\\t',' ')\n",
    "#     x = x.replace('\\s',' ')\n",
    "#     x = x.replace('   ',' ')\n",
    "#     return x\n",
    "\n",
    "# # df1['text']=df1['text'].apply(remove_stop_words)\n",
    "# df1['Language']=df1['Language'].apply(remove_stop_words)\n",
    "# df1['Edu']=df1['Edu'].apply(remove_stop_words)\n",
    "# df1['Work']=df1['Work'].apply(remove_stop_words)\n",
    "# df1['Summaries']=df1['Summaries'].apply(remove_stop_words)\n",
    "# df1['Skill']=df1['Skill'].apply(remove_stop_words)\n",
    "# df1['Member']=df1['Member'].apply(remove_stop_words)\n",
    "# df1['Writing']=df1['Writing'].apply(remove_stop_words)\n",
    "# df1['Researching']=df1['Researching'].apply(remove_stop_words)\n",
    "# df1['Honor']=df1['Honor'].apply(remove_stop_words)\n",
    "# df1['Activity']=df1['Activity'].apply(remove_stop_words)\n",
    "# df1['Curriculars']=df1['Curriculars'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>file_path</th>\n",
       "      <td>../data/input/resumes/Omar Resume 6.2019 wigg.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>220 E. Illinois | Chicago, IL 60661 | 617-955-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessionalTraining</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>LANGUAGES   Technical: R, Python, VBA, SQL, MS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edu</th>\n",
       "      <td>EDUCATION  University of Chicago | Chicago, IL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE    NIMBL, Techedge Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summaries</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skill</th>\n",
       "      <td>SKILLS AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writing</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Researching</th>\n",
       "      <td>RESEARCH EXPERIENCE Kraft Heinz People Analyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honor</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activity</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curriculars</th>\n",
       "      <td>CO-CURRICULARS  Photography: photography-omar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     35\n",
       "file_path             ../data/input/resumes/Omar Resume 6.2019 wigg.pdf\n",
       "text                  220 E. Illinois | Chicago, IL 60661 | 617-955-...\n",
       "ProfessionalTraining                                                NaN\n",
       "Language              LANGUAGES   Technical: R, Python, VBA, SQL, MS...\n",
       "Edu                   EDUCATION  University of Chicago | Chicago, IL...\n",
       "Work                   PROFESSIONAL EXPERIENCE    NIMBL, Techedge Gr...\n",
       "Summaries                                                           nan\n",
       "Skill                                                       SKILLS AND \n",
       "Member                                                              nan\n",
       "Writing                                                             nan\n",
       "Researching            RESEARCH EXPERIENCE Kraft Heinz People Analyt...\n",
       "Honor                                                               nan\n",
       "Activity                                                            nan\n",
       "Curriculars            CO-CURRICULARS  Photography: photography-omar..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1.iloc[35]\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220 E. Illinois | Chicago, IL 60661 | 617-955-7304 | oalshaye@uchicago.edu \\n\\nOmar ALShaye \\n\\n \\n\\nEDUCATION \\n\\n \\n\\nUniversity of Chicago | Chicago, IL                                                                                            Expected Winter 2020 \\nMaster of Science in Analytics, Data Science \\n\\n▪  Coursework: Statistical Analysis, Machine Learning, Optimization, Deep Learning, Data Mining, \\n\\nBusiness Applications, Data Engineering Platforms, Non-Linear Models, Big Data, Time Series \\n\\n \\nRensselaer Polytechnic Institute | Troy, NY                                                                                              May 2018 \\nDual Bachelors of Science in Industrial Management Engineering – Economics                   \\n\\n▪  Honors: Cum Laude, Rensselaer Founders Award of Excellence, Ray Palmer Baker Prize for Excellence in \\n\\nSystems Engineering, Alpha Pi Mu Honors Society Certificate of Excellence in Industrial Engineering  \\n\\n \\n\\n \\nPROFESSIONAL EXPERIENCE \\n\\n \\n\\n \\n\\n \\n\\nNIMBL, Techedge Group | Chicago, IL                                                                            June 2019 – September 2019 \\nData Intelligence Practice – Junior Consultant \\n\\n▪  Provided predictive analytics solutions for Fortune 500 CPG and Automotive clients; utilizing machine learning, \\n\\ndeep learning (computer vision), operations research, and statistical modeling techniques on R and Python  \\n\\n▪  Built visual dashboards for performance management and resource/financial planning on SAP Analytics Cloud \\n▪ \\nInvestigated a new SAP Analytics Cloud client solution that integrates R based predictive modeling capabilities  \\n\\n \\n\\nAbbott Laboratories (contract by Hiregenics) | Lake Forest, IL                                                         May 2017 – August 2017 \\nSupply Chain Operations Intern  \\n\\n▪  Built VBA algorithm to optimize box utilization (N-P problem); reduced average chargeable shipment cost by        \\n\\n29.9%, increased box utilization by 12.1%, reduced average shipment volume by 297.4 inch3 \\n▪  Performed trend analysis for top tier customers to quantify benefits of order consolidation  \\n▪  Simulated packing area using Arena; recommendation reduced packing time by 2.8 minutes per unit \\n▪  Studied outbound dock using pallet density hourly data; proposed dock composite performance index \\n\\n \\n\\n \\n\\nRESEARCH EXPERIENCE \\n\\nKraft Heinz People Analytics | Chicago, IL                                                                                 March 2019 – Present \\nCapstone Project: In and Out Analysis \\n\\n▪  Designed a supervised machine learning model to predict employee churn date and likely destination \\n▪  Built a supervised machine learning model to predict probability of recruitment success for a given candidate \\n\\nShared Vehicle Routing | Troy, NY                                                                                      May 2017 – August 2017 \\nResearcher for Professor Jennifer Pazour’s OnRout team  \\n\\n▪  Performed shared vehicle routing analysis for startup company OnRout to analyze duplicate effort by couriers \\n▪  Suggested optimal level of courier sharing; hypothetical optimal level of sharing increased stops/mile by 28%, \\n\\ndecreased total distance travelled by couriers by 19% \\n\\n▪  Built simulation TSP model for different couriers operating in a common location \\n\\n \\n\\nTelevision Manufacturing Innovation | Troy, NY                                                           January 2016 – August 2017 \\nResearcher for Professor Kenneth Simons  \\n\\n▪  Code industry-wide model for television receiver manufacturing processes and innovations. Observed 259 \\n\\nmanufacturing innovations/processes from 1941 to 1971 \\nIdentify target innovation characteristics yielding maximum economic efficiencies \\n\\n▪ \\n▪  Analyze discrepancies and compare results using Excel, Stata, and R \\n\\n \\n\\n \\n\\nSKILLS AND LANGUAGES \\n\\n \\n\\n \\n\\nTechnical: R, Python, VBA, SQL, MS Office, Tableau, Arena, Julia, SAP, Keras, TensorFlow, Stata, Hadoop, Spark, Neo4j \\nLanguages: English (fluent), Arabic (fluent)  \\n\\n \\n\\n \\n\\nCO-CURRICULARS \\nPhotography: photography-omaralshaye.com; President of UChicago and RPI Photography; Supervised 112 members \\nAlpha Pi Mu Honor Society: Promote Outreach to I.E Community; President of Rensselaer Chapter 2016-2018 \\n\\n \\n\\n \\n\\n \\n\\n\\x0c'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle = pd.read_csv('~/PycharmProjects/Resume-Parser/data/input/resumes/Kaggle_resume_dataset.csv', usecols=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.to_csv('~/PycharmProjects/Resume-Parser/data/input/resumes/Kaggle_resume_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5171348"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.getsize('data/input/resumes/Kaggle_resume_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# kaggle.text[random.randint(0, len(kaggle))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in kaggle.index:\n",
    "#     if kaggle.text.loc[i].find('PROFESSIONAL ACTIVITIES') != -1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts = 0\n",
    "# for i in kaggle.index:\n",
    "#     if kaggle.text.loc[i].lower().find('\\\\xa8') != -1:\n",
    "#         kaggle.text.loc[i] = kaggle.text.loc[i].replace('\\\\xa8', '')\n",
    "#         counts = counts + 1\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.drop(830, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle = kaggle.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
