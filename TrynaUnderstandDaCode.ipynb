{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To look at sections of the YAML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# with open('/Users/anneitrheim/PycharmProjects/Capstone/confs/config.yaml', 'r') as stream:\n",
    "#     try:\n",
    "#         data_loaded = yaml.safe_load(stream)\n",
    "#     except yaml.YAMLError as exc:\n",
    "#         print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame()\n",
    "# for i in data_loaded['extractors']['universities']:\n",
    "#     if type(i) == list:\n",
    "#         df = df.append(pd.Series(i), ignore_index=True)\n",
    "#     else:\n",
    "#         df = df.append(pd.Series(i), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['one', 'two', 'three']\n",
    "# df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For word2vec on the resumes we have in our repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/output/resume_parsed.csv')\n",
    "df.drop(['extension'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "import re\n",
    "   \n",
    "def remove_stop_words(x):\n",
    "    try:\n",
    "  \n",
    "        x = x.replace('___',' ')\n",
    "        x = x.replace('\\n',' ')\n",
    "        x = x.replace('\\r',' ')\n",
    "        x = x.replace('\\t',' ')\n",
    "        x = x.replace('\\s',' ')\n",
    "        x = x.replace('   ',' ')\n",
    "\n",
    "        x = re.sub('[^A-Za-z ]+', '', x)\n",
    "        \n",
    "        word_tokens = word_tokenize(x)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        return ' '.join(filtered_sentence)\n",
    "    except:\n",
    "        print(x.values)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "resumes=df['text'].apply(remove_stop_words)\n",
    "# store as list of lists of words\n",
    "resumes_ted = []\n",
    "for sent_str in resumes:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "    resumes_ted.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM=300\n",
    "w2v=Word2Vec(resumes_ted, #the list of split resumes\n",
    "             size=EMB_DIM, #the dimensionality of the embedding vector\n",
    "             window=5, #Maximum distance between the current and predicted word within a sentence\n",
    "             min_count=3, #Ignores all words with total frequency lower than this (to keep only valid real words)\n",
    "             negative=15, #Negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20)\n",
    "             iter=10, #Number of iterations (epochs) over the corpus\n",
    "             workers=multiprocessing.cpu_count()) #number of threads being used\n",
    "vectors=w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intelligence', 0.8516367673873901),\n",
       " ('platforms', 0.845102846622467),\n",
       " ('logic', 0.827791690826416),\n",
       " ('networks', 0.8258625268936157),\n",
       " ('domain', 0.8074485063552856),\n",
       " ('digital', 0.7982150912284851),\n",
       " ('visualization', 0.7959266304969788),\n",
       " ('modeling', 0.7913885116577148),\n",
       " ('automation', 0.7723206281661987),\n",
       " ('engine', 0.7649234533309937)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.most_similar(positive=['analytics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the number index before aggregating sub-sections:\n",
    "(to see if it parsed correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_csv('data/output/resume_summary.csv')\n",
    "df = pd.read_csv('data/output/resume_parsed.csv')\n",
    "df.drop(['extension'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.index:\n",
    "#     df.file_path[i] = df.file_path[i][29:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Columns that are not used:\\n')\n",
    "# for i in df.columns:\n",
    "#     if len(set(df[i])) == 1:\n",
    "#         print(i[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_profiling --no-deps\n",
    "# import pandas_profiling\n",
    "# df.profile_report(style={'full_width':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    ../data/input/resumes/LT CV.pdf\n",
      "Name: file_path, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExperienceLocation</th>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EducationLocation</th>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SoftwareLocation</th>\n",
       "      <td>3891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkillsLocation</th>\n",
       "      <td>3901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name\n",
       "ExperienceLocation   217\n",
       "EducationLocation   3720\n",
       "SoftwareLocation    3891\n",
       "SkillsLocation      3901"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(df.loc[13])\n",
    "x.columns = ['Name']\n",
    "print(x.loc['file_path'])\n",
    "x[x.Name != -1].drop(['file_path','text'], axis=0).sort_values(by='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in df.index[255:]:\n",
    "#     if df.text.loc[i].find('PROFILE') != -1 :\n",
    "#         if df.text.loc[i].find('\\\\nPROFILE\\\\n') != -1 :\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".replace(':', ' ')\n",
    ".replace(':', ' ').replace('-', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or looking at the aggregated df to see if it parsed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('data/output/resume_sections.csv')\n",
    "df1.drop(['extension'], axis=1, inplace=True)\n",
    "\n",
    "import re\n",
    "def remove_stop_words(x):\n",
    "    x = str(x)\n",
    "    x = x.replace('___',' ')\n",
    "    x = x.replace('\\n',' ')\n",
    "    x = x.replace('\\r',' ')\n",
    "    x = x.replace('\\t',' ')\n",
    "    x = x.replace('\\s',' ')\n",
    "    x = x.replace('   ',' ')\n",
    "    return x\n",
    "\n",
    "# df1['text']=df1['text'].apply(remove_stop_words)\n",
    "df1['Language']=df1['Language'].apply(remove_stop_words)\n",
    "df1['Edu']=df1['Edu'].apply(remove_stop_words)\n",
    "df1['Work']=df1['Work'].apply(remove_stop_words)\n",
    "df1['Summaries']=df1['Summaries'].apply(remove_stop_words)\n",
    "df1['Skill']=df1['Skill'].apply(remove_stop_words)\n",
    "df1['Member']=df1['Member'].apply(remove_stop_words)\n",
    "df1['Writing']=df1['Writing'].apply(remove_stop_words)\n",
    "df1['Researching']=df1['Researching'].apply(remove_stop_words)\n",
    "df1['Honor']=df1['Honor'].apply(remove_stop_words)\n",
    "df1['Activity']=df1['Activity'].apply(remove_stop_words)\n",
    "df1['Curriculars']=df1['Curriculars'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>file_path</th>\n",
       "      <td>../data/input/resumes/Kyle Parochetti Resume.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Kyle Parochetti\\n\\n1100 W Montrose Ave, Chicago, IL, 60613 \\n\\n(563) 650-6989 \\nkdvp13@gmail.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessionalTraining</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edu</th>\n",
       "      <td>EDUCATION UNIVERSITY OF NORTHERN IOWA B.A. Accountancy (May 2015)  • •  President, Treasurer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work</th>\n",
       "      <td>WORK EXPERIENCE RedRidge Diligence Services - Chicago, IL Analyst  Mar 2017 – Present  Lead ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summaries</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skill</th>\n",
       "      <td>CREDENTIALS AND LICENSES  Certified Public Accountant (Iowa, Active License # O13806)  Basic ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Member</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writing</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Researching</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honor</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activity</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curriculars</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       33\n",
       "file_path                                                                ../data/input/resumes/Kyle Parochetti Resume.pdf\n",
       "text                  Kyle Parochetti\\n\\n1100 W Montrose Ave, Chicago, IL, 60613 \\n\\n(563) 650-6989 \\nkdvp13@gmail.com...\n",
       "ProfessionalTraining                                                                                                  NaN\n",
       "Language                                                                                                              nan\n",
       "Edu                   EDUCATION UNIVERSITY OF NORTHERN IOWA B.A. Accountancy (May 2015)  • •  President, Treasurer and...\n",
       "Work                   WORK EXPERIENCE RedRidge Diligence Services - Chicago, IL Analyst  Mar 2017 – Present  Lead ful...\n",
       "Summaries                                                                                                             nan\n",
       "Skill                 CREDENTIALS AND LICENSES  Certified Public Accountant (Iowa, Active License # O13806)  Basic ver...\n",
       "Member                                                                                                                nan\n",
       "Writing                                                                                                               nan\n",
       "Researching                                                                                                           nan\n",
       "Honor                                                                                                                 nan\n",
       "Activity                                                                                                              nan\n",
       "Curriculars                                                                                                           nan"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1.iloc[33]\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SKILLS  MS Office: Word, Excel and PowerPoint  Accpac Telmera: Access Database  Hyperion and HFM  NOTICE PERIOD  3 months   \\x0c SOFTWARE '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.Skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle = pd.read_csv('~/PycharmProjects/Resume-Parser/data/input/resumes/Kaggle_resume_dataset.csv', usecols=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.to_csv('~/PycharmProjects/Resume-Parser/data/input/resumes/Kaggle_resume_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5342701"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.getsize('data/input/resumes/Kaggle_resume_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kaggle.text[random.randint(0, len(kaggle))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts = 0\n",
    "# for i in kaggle.index:\n",
    "#     if kaggle.text.loc[i].lower().find('\\\\n \\\\n') != -1:\n",
    "#         kaggle.text.loc[i] = kaggle.text.loc[i].replace('\\\\n \\\\n', '\\\\n\\\\n')\n",
    "#         counts = counts + 1\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.drop(649, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle = kaggle.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
